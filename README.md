## A Game about strategic information revelation with biased committee members
This experiment is designed to uncover the strategic information sharing of individuals in a committee situation when faced with biased information updating. Formal theory showed that in a committee with rational agents complete information revelation is possible if and only if some "closeness condition" is fulfilled concerning the individual theresholds of reasonable doubt of committee members. In other words, whenever these thresholds are spread further apart and known, it is not rational for committee members to reveal their signal truthfully (or at all) (Coughlan 2000, Schulte 2010). In an extension of the model by Schulte (2010) I show that the existence of complete correlation neglect for some agents reduces the existence of full information revelation equilibrium to a situation in which rational individuals and those neglecting correlation end up with identical beliefs, meaning correlation neglect is not biasing the posterior belief of those individuals. 

This result shows that whenever individuals who have to make a common decision face a situation in which the same prior information and the same signals lead to different posterior beliefs, a pivotal voter has an incentive to share signals strategically. Strategic signal sharing can either mean lying about the direction of their signal or hiding a signal that was received. While theoretic models can show how perfectly rational actors would "in equilibrium" act whenever they face a situation in which individuals update their information in a non rational way, there is no conclusive evidence about human behavior in these situations. This experiment is meant to create such evidence by placing humans in a committee decision with bots that perform biased upadting. Humans can affect bots behavior by their information sharing behavior prior to some voting stage. The results show us to which degree humans actually understand in an oversimplified setting how their information sharing behavior might affect group decision making.

## Previous experimental research on committee decision making with limited communication
Previous experimental research on decision making in committees was designed to understand the effect of different decision makign rules on the voting behavior of individuals. Their findings suggested that individuals act less strategic than predicited by formal models. Furthermore, communication always improved the performance of those committees (Guarnaschelli et al. 2000, Goeree and Yariv 2005). In these experiments individuals played together to decide on the state of the world which was depicted as a blue or a red urn. All committee members received individual and independent signals that were correlated with the true state of the world. In some experimental settings participants were also able to participate in a straw vote to signal their own private signal to their committee members.

These experiments can help to understand the strategic behavior of individuals concerning rules. However, they are unable to show the strategic behavior concerning a difference in the information processing of individuals. The first and most important reason is, that in these experiments participants do not interact long enough to understand the information processing of the other individuals. Further, the exercise is so abstract that several possible cognitive biases like confirmation bias do not affect information processing. To solve these problems and enable us to observe strategic information sharing behavior caused by differences in information processing, I suggest to play a variant of the original urn draw experiment but only with bots. Bots have the advantage that their information processing, sharing and voting behavior can be determined by the experimenter. This makes the behavior known. Further it enables the experimenter to tell the participants how the committee members react. This puts participants in the position to affect the final decision with their information sharing behavior. The exact experimental design is described in the next paragraph.

## Experimental task
In the experiment one human participant interacts with two bots in a three member committee. The committee has to make a decision whether they face a blue or a red urn based on signals they received. A priori both urns have the same possibility to be chosen. While the red urn contains 6 red and 4 blue balls, the blue contains 6 blue and 4 red balls. Committee members receive between 0 and 3 signals in form of independent draws from the urn that was was chosen. Each committee member receives each possible signal with a probability of p=0.7. The following table shows the probability that committee members receive a certain number of signals:

|number of signals | probability|
|------------------|------------|
|0                 |0.027       |
|1                 |0.189       |
|2                 |0.441       |
|3                 |0.343       |

After receiving their signals participants can decide to show their signals to the other committee members or not. The decision can be made individually for each signals the participant received. Signals are assumed to be verifiable and therefore they can only be hidden or presented but not changed. Since the number of signals that a participants received is unknown, neither bots nor humans can infer whether signals were hidden or not. After sharing or pooling their signals, committee members have to make an individual vote whether the urn is red or blue. The committee decision is made by single majority.

## Treatments: Bots
To adjust the own sharing behavior to the information processes of other committee members, they have to understand the strategies and information behavior of bots. Bots have a full information sharing strategy and sincere voting strategy, meaning they share all signals they receive and vote according their posterior beliefs. The strategy is known by all participants. However, bots have different updating functions depending on the treatment group that participants are in:

| Group               | Condition to vote red               | condition to vote blue      |
|---------------------|-------------------------------------|-----------------------------|
| Control             | \#red - \#blue >= 0          |\#red - \#blue < 0           | 
| Low Bias Treatment  | 1.3 * \#red - \#blue \geqslant 0| 1.3\cdots \#red - \#blue < 0|
| High Bias Treatment | 1.7$$ \times $$ \#red - \#blue \geqslant 0| 1.7\cdots \#red - \#blue < 0|

Based on those treatment groups and the (limited) rationality that humans present in these experiments, I have the following (preliminary) hypothesis about the sharing behavior of individuals:

H1: The higher the bias that bots have in information processing, the more frequently do humans hide information.

However, hiding information might be a risky strategy as it is an active manipulation of the information pool of participants. More risk loving participants should be more willing to manipulate the information they present in order to change the bots behavior:

H2: The more risk loving a participant is, the more frequently does the participant hide information.

I plan to use a risk task by Holt and Laury (2002). This task is a standard measurement for the risk behavior of individuals and gives a relatively finegrained measurement of risk attitudes.

## Sequence of play
After a short welcome and information about rule and rights for the participants, the participants receive the information about the game that they will be playing. the information is the same for all treatment groups besides the information about the information processing of bots. The participants have to show that they understood the rules and the functioning of bots in short quiz. After the quiz, the participants play three rounds of the committee game iwht two bots as described in the previous instructions. Between the first and the second round participants receive now feedback about the result of their previous task. After the second round participants receive the feedback whether the committee decision in the two previous rounds was correct or not. This means that in the third round participants might have learned from their behavior in previous round while learning was not possible from teh first to the second round. After the committee decision game, participants perform the risk task by Holt and Laury (2002) and fill out a questionnaire. The questionnaire includes questions about age, sex and education of the participants. Further the participants have to answer questions from the cognitive reflection test (Frederick 2005). After that Ã¼articipants are informed about their payoffs.

## Time and Payment
The whole experiment is planned to be not longer (actually shorter) than 30 minutes. I plan 10 minutes each for: 1. introduction and quiz, 2. the committee game, 3. risk task and questionnaire. To make the participation in the experiment attractive I plan to pay up to 8$ for participation depending on the performance of the participants or their committee. Participants receive a participation fee of 2$ and there is a flexible payoff of up to 6$. That means each correct committee decision in the committee game is worth 2$. 

## Number of participants 
Well, the number of participants certainly depends on teh budget available. For now I know that I have enough money for up to 40 participants. I plan on having 10 participants in the control and 15 in each treatment group.
